I"D<h2 id="1-报告内容">1 报告内容</h2>

<p>第一次在帝都现场参加技术talk的沙龙，比学校的talk要应用性实际的多。</p>

<p>第一个报告是百度语音部门负责人贾磊，主要讲了百度语音搜索在DNN领域的一些经验。百度成立了第一个研究院，Institute of Deep Learning，简称IDL。 由于Deep Learning在语音及多媒体领域面对海量数据的优越性，Google、Miscrosft等公司都开始投入大量的人力、物力做这样一件事情。
没带笔记本过去，凭记忆力列几个关键点。</p>

<ul>
  <li>处理流程为客户端编码、上传、服务器端处理、下放</li>
  <li>训练样本为10亿级，如考虑抗噪，会到百亿数量级</li>
  <li>MS的隐层深度为10层，Google的隐层数目为6层左右，输出层为9000维左右</li>
  <li>SGD（随机乱序），异步SGD，利用近似二阶梯度i信息为训练中重要方法</li>
  <li>节点间通信的带宽为主要瓶颈</li>
  <li>单个GPU核的计算能力相当于未优化的CPU核的400～500倍</li>
  <li>Google有chrome，所以可以在浏览器里加入语音的采集模块，百度没有多媒体采集的客户端，很受限制。</li>
</ul>

<p>第二个报告是IBM中国研究院的秦勇老师。分享了IBM在语音处理方面的进展，主要是大的picture</p>

<ul>
  <li>Itrans（IBM speech transcription server）能够将视频中的语音翻译成文本信息。这个应用在国外的客服领域应用较多，主要是在金融等行业。除此之外，对于很多talk形成文本话非常有意义</li>
  <li>讲解了Watson背后的技术DeepQA，虽然Watson目前只应用在娱乐节目上，但是可以将其扩展到如医疗等方向上，因为医学的知识不断的发展，而医生整理知识的工作是可以由Watson代替的</li>
  <li>分享了邮件的主题可视化，增加了直观性</li>
</ul>

<p>提出了几个有意思的点子：</p>

<ul>
  <li>有人在考虑实现如雅思、托福类的口语自动判卷。IBM没有做过商用，但是针对印度的口音做过类似的应用。IBM表示没有考虑语义，看来语义还是很难做的。如果这个效果好，简直可以大赚一笔</li>
  <li>可以实现学习如希特勒的说话特征，然后自动的根据特点生成语音。这个略犀利，如果做好了，以后接电话要小心了。</li>
  <li>通话质量的可视化</li>
</ul>

<p>感想：</p>

<ul>
  <li>DNN比拼的简直是工程实现能力，架构才是王道啊，机器+架构实现+数据源 是真正的瓶颈</li>
  <li>有想法，有技术，敢闯的人在帝都有这种交流的机会真是不错</li>
  <li>百度的浏览器、输入法等入口工具都起步太晚，导致了数据上的先天缺陷</li>
  <li>技术的交流是必须的，故步自封是要吃苦头的</li>
</ul>

:ET